<br>
  
# 데이터 랭글링(Data Wrangling) 또는 데이터 멍잉(Data Munging)

멍잉(munging)은 전처리, 파싱, 필터링과 같이 데이터를 이리저리 핸들링한다는 뜻이다..사실 이 단어는 컴퓨터로 데이터를 처리하는 사람들 사이에서 많이 쓰이는 따끈따끈한 신조어이다.  - 전희원 저 'R로 하는 데이터 시각화' 52쪽 


# **Pandas**

고수준의 자료구조(Series, DataFrame)를 지원한다.


<br>

# 📝 **Series**

일련의 객체를 기억할 수 있는 1차원 배열 구조를 갖는다.  
자동으로 index가 부여된다.

```py
import pandas as pd
import numpy as np

#Series
obj = pd.Series([3, 7, -5, 4])  #list
obj = pd.Series((3, 7, -5, 4))   #tuple
#obj = pd.Series({3, 7, -5, 4})  #set type은 오류발생 - set은 순서가 없기 때문

print(obj, ' ', type(obj))

obj2 = pd.Series([3, 7, -5, 4], index = ['a', 'b', 'c', 'd'])

print(obj2, ' ', type(obj2))

print(sum(obj2))
print(np.sum(obj2))
print(obj2.sum())
print(obj2.mean())
print(obj2.std())
print()

print(obj2.values)
print(obj2.index)
```


<br>

### 🌼 **dict type으로 Series 생성**



```py
names = {'mouse':5000, 'keyboard':25000, 'monitor':450000}
print(names, type(names))

obj3 = pd.Series(names)  #key값이 index가 됨
print(obj3, ' ', type(obj3))
print(obj3[1])
print(obj3['keyboard'])
print()

obj3.index = ['마우스','키보드','모니터']
print(obj3, ' ', type(obj3))
print()

obj3.name = '상품가격'
print(obj3)
```

<br>

## 👉 **Slicing 슬라이싱**

```py
obj2 = pd.Series([3, 7, -5, 4], index = ['a', 'b', 'c', 'd'])

print(obj2['a'])         #값출력
print(obj2[['a']])       #index와 값 함께 출력
print(obj2[['a', 'b']])
#print(obj2['a', 'c'])   #오류
print(obj2['a':'c'])     #콜론을 사용하자
print()

print(obj2[2])
print(obj2[1:4])
print(obj2[[2, 1]])
print()

print(obj2 > 0)
print('a' in obj2)
```

<br>

# 📝 **Data Frame**


```py
df = pd.DataFrame(obj3)
print(df, ' ', type(df))

data = {
    'irum':['병구','영진','우솔','기준','은별'],
    'juso':('역삼동','신당동','역삼동', '역삼동','신사동'),
    'nai':[23, 25, 33, 30, 35],
}

print(data)
print(type(data))
```


<br>

## 👉 **DataFrame 데이터 다루기**


```py
from pandas import DataFrame, Series
frame = DataFrame(data)

print(frame)
print(frame['irum'])
print(frame.irum, ' ', type(frame.irum))
```


### 전치

```py
frame2 = DataFrame(data, columns=['irum','nai','juso','tel'], index=['a','b','c','d','e'])  #컬럼순서를 바꾸고, 새로운 컬럼생성
print(frame2)

frame2['tel'] = '111-1111'
print(frame2)

val = Series(['222-222','333-1111','444-1111'], index=['b','c','e'])
frame2['tel'] = val
print(frame2)

#전치
print(frame2.T)

#list type으로 출력
print(frame2.values)   #2차원형태로
print(type(frame2.values))  
print(frame2.values[0, 2])
print(frame2.values[0:2])

frame3 = frame2.drop('d', axis=0)   #행삭제. axis=0:기본값
print(frame3)

frame4 = frame2.drop('tel', axis=1) #열삭제
print(frame4)
```


<br>

## 👉 **정렬, 순위, count : `.sort_index(), .rank(), .value_counts()`**

```py
print(frame2.sort_index(axis=0, ascending=False))
print(frame2.sort_index(axis=1, ascending=False))

print(frame2.rank(axis=0))

print(frame2['juso'].value_counts())

data = {
    'juso':['강남구 역삼동', '중구 신당동', '강남구 대치동'],
    'inwon':[23, 25, 15]
}

fr = DataFrame(data)
print(fr)
print()

result1 = Series([x.split()[0] for x in fr.juso])
print(result1)

result2 = Series([x.split()[1] for x in fr.juso])
print(result2)
```

<br>

# 📝 Series의 재색인 : `.reindex()`

```py
data = Series([1, 3, 2], index = (1, 4, 2))
print(data)

data2 = data.reindex((1,2,4))
print(data2)
```


## 👉 재색인하며 값 채우기


```py
data3 = data2.reindex([0, 1, 2, 3, 4, 5])
print(data3) #값이 존재하지 않는 항목들은 NaN
print()

data3 = data2.reindex([0, 1, 2, 3, 4, 5], fill_value = 777)  #특정값으로 채우기
print(data3)
print()

data3 = data2.reindex([0, 1, 2, 3, 4, 5], method = 'ffill')  #forward fill : NaN의 바로 앞의 값으로 대체
#data3 = data2.reindex([0, 1, 2, 3, 4, 5], method = 'pad')   #위와 동일
print(data3)
print()

data3 = data2.reindex([0, 1, 2, 3, 4, 5], method = 'bfill')  #back fill : NaN의 바로 다음 값으로 대체
print(data3)
print()
```


<br>

# 📝 **DataFrame의 Slicing**

```py
import numpy as np

df = DataFrame(np.arange(12).reshape(4, 3), index=['1월','2월','3월','4월'], columns=['강남','강북','서초'])
print(df)
print()

print(df['강남'])
print()
print(df['강남'] > 3)
print()
print(df[df['강남'] > 3])
print()

print(df < 3)
df[df < 3] = 0
print(df)
```

<br>

## 👉 **Label 기능 : `.loc(), .iloc()`**

loc: 라벨 지원, iloc: 인덱스라벨지원

```py
#loc
print(df.loc['4월'])
print(df.loc['3월',])
print(df.loc[:'2월'])
print(df.loc[:'2월', ['서초']])

#iloc
print(df.iloc[2])
print(df.iloc[2, :])
print()

print(df.iloc[:3])
print(df.iloc[:3, 2])
print(df.iloc[:3, 1:3])
```

<br>

# 📝 **산술연산**


## Series

```py
s1 = Series([1,2,3], index=['a','b','c'])
s2 = Series([4,5,6,7], index=['a','b','c','d'])

print(s1)
print(s2)

print(s1 + s2)  #같은 index끼리 연산. 불일치할 경우 NaN
print(s1.add(s2))
print(s1 * s2)
```

## DataFrame

```py
df1 = DataFrame(np.arange(9.).reshape(3, 3), columns = list('one'), index = ['서울','인천','수원'])
print(df1)
print()

df2 = DataFrame(np.arange(12.).reshape(4, 3), columns = list('one'), index = ['서울','인천','부산','광주'])
print(df2)

print(df1 + df2)
print(df1.add(df2, fill_value = 0))  #NaN은 0으로 채운 후 연산

print(df1 * df2)
print(df1.multiply(df2, fill_value = 1))  #NaN은 1로 채운 후 연산
```

<br>

## Series와 DataFrame 간의 연산

DataFrame과 Series 간의 산술연산은 Series의 색인을 DataFrame의 컬럼에 맞추고 아래행으로 전파한다.  -> Broadcasting

```py
df1 = DataFrame(np.arange(9.).reshape(3, 3), columns = list('one'), index = ['서울','인천','수원'])
seri = df1.iloc[0]
print(seri)

print(df1 - seri)  
```

<br>

# 📝 **결측치 처리**

```py
df = DataFrame([[1.3, np.nan], [7, -4.3], [np.NaN, np.NAN], [0.5, -1]], columns = ['one','two'])
print(df)
print()

#print(df.drop(1))
print(df.isnull())
print(df.notnull())
```


## 👉 `.dropna()`

```py
print(df.dropna())
print()
print(df.dropna(how='any'))       #how='any': NaN이 하나라도 있으면 해당 행 제거
print()

print(df.dropna(how='all'))       #how='any': 행 전체가 NaN이라면 해당 행 제거. 하나라도 다른 값이 있으면 제거되지 않는다.
print()

print(df.dropna(subset=['two']))  #subset=['two']: 'two'컬럼에 NaN이 존재하는 행 제거. 특정열에 NaN이 있는 해당 행 제거
print()

print(df.dropna(axis='rows'))     #NaN이 포함된 행 모두 제거
print()

print(df.dropna(axis='columns'))  #NaN이 포함된 열 모두 제거
```

<br>

## 👉 `.fillna()`

```py
print(df.fillna(0))  #NaN 0으로 대체

기본적으로 NaN은 연산에서 제외한다.  

print(df.sum())
print(df.sum(axis=0))  #행의 합
print(df.sum(axis=1))  #열의 합

print()
print(df)
print(df.mean())
print(df.mean(axis=1))
print(df.mean(axis=0, skipna = True))   #기본값
print(df.mean(axis=0, skipna = False))  #NaN 포함하여 연산
```

<br>

# 📝 **그 외 함수들**


## `.idxmax()` : 최대값의 index 출력

```py
print(df.max())
print(df.idxmax())
```

## `.describe()` : 요약통계량

```py
print(df.describe())  
```

<br>

# 📝 **DataFrame의 형태 변경**

`.reshape() ,.stack(), .unstack()`

```py
import numpy as np
import pandas as pd

df = pd.DataFrame(1000 + np.arange(6).reshape(2, 3), index=['서울','대전'], columns=['2020','2021','2022'])
print(df)
print()

#index를 기준으로 컬럼 쌓기
df_row = df.stack()
print(df_row)
print()

#원래대로
df_col = df_row.unstack()
print(df_col)
```

<br>

## 👉 **범주화 : `.cut()`**

```py
price = [10.3, 5.5, 7.8, 3.6]
cut = [3, 7, 9, 11]  #구간 기준 값

result_cut = pd.cut(price, cut)
print(result_cut)
print()

print(pd.value_counts(result_cut))

datas = pd.Series(np.arange(1, 1001))
print(datas.tail())
print()

cut2 = [1, 500, 1000]
result_cut2 = pd.cut(datas, cut2)

print(result_cut2)
print()
print(pd.value_counts(result_cut2))
print()

result_cut3 = pd.qcut(datas, 5)
print(result_cut3)
print()
print(pd.value_counts(result_cut3))
```

<br>

## 👉 **Group 별로 작업하기 : `.groupby()`**


`.agg` : 소계를 구하는 함수

```py
group_col = datas.groupby(result_cut2)
print(group_col)
print()

print(group_col.agg(['count','mean','std','min']))

#함수로 만들어 보기
def summary_func(gr):
  return {
      'count':gr.count(),
      'mean':gr.mean(),
      'std':gr.std(),
      'min':gr.min()
  }

print(group_col.apply(summary_func))
print()
print(group_col.apply(summary_func).unstack())
```


## 👉 **자료 병합하기**

`.merge()` : key를 기준으로 병합한다.




### 🌼 공통 컬럼이 있는 경우

```py
df1 = pd.DataFrame({'data1':range(7), 'key':['b','b','a','c','a','a','b']})
print(df1)
print()

df2 = pd.DataFrame({'key':['a','b','d'], 'data2':range(3)})
print(df2)
print()

#공통컬럼이 있는 데이터들에 대해서만 작업
#SQL의 INNER JOIN
print(pd.merge(df1, df2, on='key'))
print()
print(pd.merge(df1, df2, on='key', how='inner'))  #위와 동일
print()

#OUTER JOIN
print(pd.merge(df1, df2, on='key', how='outer'))
print()

#LEFT OUTER JOIN
print(pd.merge(df1, df2, on='key', how='left'))
print()

#RIGHT OUTER JOIN
print(pd.merge(df1, df2, on='key', how='right'))
```

<br>

### 🌼 공통 컬럼이 없는 경우

`.concat()`

```py
df3 = pd.DataFrame({'key2':['a','b','d'], 'data2':range(3)}) #df1, df2와 공통 컬럼X
print(df3)
print()

#INNER JOIN
print(pd.merge(df1, df3, left_on='key', right_on='key2'))
print()

print(pd.concat([df1, df3])) #대응되지 않으면 NaN
print()

#이어붙이기
print(pd.concat([df1, df3], axis=0))
print()
print(pd.concat([df1, df3], axis=1))
print()
```

<br>

## Series의 병합


```py
s1 = pd.Series([0,1], index = ['a','b'])
s2 = pd.Series([2,3,4], index = ['c','d','e'])
s3 = pd.Series([5,6], index = ['f','g'])

print(pd.concat([s1, s2, s3], axis=0))
```

<br>

## 👉 **Pivot table 피벗테이블**

데이터의 행렬을 재구성하여 연산 후 결과를 출력

```py
data = {'city':['강남','강북','강남','강북'],
        'year':[2000,2001,2002,2002],
        'pop':[3.3,2.5,3.0,2.0]}

df = pd.DataFrame(data)
print(df)
print()
print(df['pop'].describe())
```

<br>

### `.pivot()`


```py
print(df.pivot('city','year','pop'))  #행,열,계산할 컬럼. 구조를 재구성하여 출력
print()
print(df.set_index(['city','year']).unstack())  #.set_index() : 기존의 행 index를 제거하고 첫번째 열을 인덱스로 설정
print()

print(df.pivot('year','city','pop'))
print()
print(df.set_index(['year','city']).unstack()) 
print()
```

<br>

### `.pivot_table()` : 연산 가능

```py
print(df.pivot_table(index=['city']))
print()

print(df.pivot_table(index=['city'], aggfunc = np.mean))  #aggfunc=np.mean: 기본값. 위와 동일
print()

print(df.pivot_table(index=['city','year'], aggfunc = np.mean))
print()

print(df.pivot_table(index=['city','year'], aggfunc = [len, np.sum]))
print()

#연산 대상 지정
print(df.pivot_table(values=['pop'], index='city', aggfunc=np.mean))  
print()

print(df.pivot_table(values=['pop'], index='city', aggfunc = len))
print()

print(df.pivot_table(values=['pop'], index='year', columns='city'))
print()

print(df.pivot_table(values=['pop'], index='year', columns='city', margins=True))
print()

print(df.pivot_table(values=['pop'], index='year', columns='city', margins=True, fill_value=0))

#groupby 사용
hap = df.groupby(['city'])
print(hap)
print(hap.sum())
print()

print(df.groupby(['city']).sum())  #한 줄로 표현
print()

print(df.groupby(['city','year']).sum())
```

<br>

# 📝 **Pandas File I/O**

<br>

## 👉 파일 읽기

```py
import pandas as pd

#df = pd.read_csv('../testdata/ex1.csv')
df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex1.csv')
print(df, type(df))
print()

df = pd.read_table('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex1.csv', sep=',')
print(df)
print()

#df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex2.csv')
df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex2.csv', header=None)
print(df)
print()

df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex2.csv', header=None, names=['a','b'])
print(df)  #뒤에서부터 컬럼명 부여
print()

df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex2.csv', header=None, names=['a','b','c','d','e'])
print(df)  #컬럼명부여
print()

df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex2.csv', header=None, names=['a','b','c','d','msg'],
                 index_col = 'msg')  #msg 컬럼을 행 인덱스로
print(df)

#df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex3.txt')
print(df)
print()

df = pd.read_table('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex3.txt', sep='\s+') #공백이 0개 이상. 정규표현식 사용
print(df)
print()

df = pd.read_table('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/ex3.txt', sep='\s+',
                   skiprows=[1, 3])  #1행, 3행 제외 
print(df)
print()

abc = pd.read_fwf('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/data_fwt.txt', 
                  widths=(10, 3, 5), encoding='utf-8', header=None, names=('date','name','price'))

print(abc)
print()
print(abc['date'])
```

<br>

## Chunk 단위로 파일 읽기

```py
import pandas as pd

#객체로 생성
abc = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/data_csv2.csv', header=None, chunksize=3)
print(abc)
print()

for piece in abc:
  #print(piece)
  print(piece.sort_values(by=2, ascending=True))
```

<br>

## 👉 파일 저장


### HTML로 내보내기


```py
import pandas as pd

items = {'apple':{'count':10, 'price':2000}, 'orange':{'count':5, 'price':1000}}
df = pd.DataFrame(items)
print(df)

print(df.to_html())
```

<br>

### CSV로 내보내기

```py
df.to_csv('/content/drive/MyDrive/work/aa1.csv', sep=',')
df.to_csv('aa2.csv', sep=',', index=False)
df.to_csv('aa3.csv', sep=',', index=False, header=False)

data = df.T
data.to_csv('aa4.csv', sep=',', index=False, header=True)
print(pd.read_csv('aa4.csv'))
```

<br>

### Excel로 내보내기

``````py
!pip install xlsxwriter
```

```py
df2 = pd.DataFrame({'data':[10, 20, 30, 30, 15]})
print(df2)
print()

#1)
#Excel 파일을 다룰 때는 반드시 sheet name을 써줘야한다.
writer = pd.ExcelWriter('aa5.xlsx', engine='xlsxwriter')
df2.to_excel(writer, sheet_name='Sheet1')
writer.save()

#2)
df2.to_excel('aa55.xlsx')

#3) Excel File 읽기
kbb = pd.ExcelFile('aa55.xlsx')
print(kbb.sheet_names)
df3 = kbb.parse('Sheet1')
print(df3)
print()

#4)encoding
df4 = pd.read_excel('aa5.xlsx', sheet_name='Sheet1')
print(df4)
```
